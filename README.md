---

# ‚≠ê Short Description (FER-2013 + AlexNet + Real-Time)

**Emotion recognition system built using the AlexNet architecture, trained on the FER-2013 facial expression dataset and integrated with real-time computer vision for live emotion detection using a webcam.**

---

# üìò README.md

# Emotion Recognition using AlexNet on FER-2013 with Real-Time Computer Vision

This project implements a complete **emotion recognition pipeline** using the **AlexNet deep CNN architecture**, trained on the **FER-2013 (Facial Expression Recognition)** dataset.
The system performs end-to-end processing: **data loading, preprocessing, model training, evaluation, and real-time emotion detection using OpenCV**.

With real-time integration, the model can classify emotions directly from a webcam feed, making it suitable for interactive and applied AI systems.

---

## üìå Highlights ‚Äì Full Work Done in This Project

### ‚úî Dataset: FER-2013

You used the FER-2013 dataset, which contains:

* **35,887** 48√ó48 grayscale images
* **7 emotion classes:**

  * Angry
  * Disgust
  * Fear
  * Happy
  * Sad
  * Surprise
  * Neutral
* Training, Public Test, Private Test splits

You processed this raw dataset for AlexNet's requirements.

---

## ‚úî Data Preprocessing

* Read the FER-2013 CSV dataset
* Converted pixel strings to numpy arrays
* Resized grayscale 48√ó48 images to **227√ó227√ó3** (AlexNet format)
* Normalized pixel values
* One-hot encoded emotion labels
* Created train/validation/test splits

---

## ‚úî Data Augmentation

Used real-time augmentation to improve performance:

* Rotation
* Horizontal Flip
* Zoom
* Width/Height Shift
* Brightness Variations
* Rescale + Batch Generation

---

## ‚úî AlexNet Architecture Implementation

You successfully recreated a full AlexNet model:

* Conv + ReLU layers
* MaxPooling
* Deep convolution blocks
* Fully connected 4096 √ó 4096 layers
* Dropout regularization
* Softmax output for **7 emotion classes**

Optimized and compiled with:

* Loss: Categorical Crossentropy
* Optimizer: Adam/SGD
* Metric: Accuracy

---

## ‚úî Model Training

* Trained the model on augmented FER-2013 images
* Visualized training/validation accuracy & loss curves
* Tuned epoch count, learning rate, batch size
* Saved the model for later use in real-time testing

---

## ‚úî Model Evaluation

* Evaluated on FER-2013 test set
* Calculated classification accuracy
* Displayed confusion matrix
* Shown correctly/incorrectly predicted images

---

# üî• Real-Time Emotion Recognition (Your Key Feature)

You integrated OpenCV with your trained AlexNet model to enable **live emotion detection**.

### ‚úî Real-Time Pipeline

Using webcam input:

1. Capture frame using OpenCV
2. Detect face (Haar Cascade or DNN)
3. Crop face region
4. Resize to 227√ó227
5. Normalize
6. Predict emotion using trained AlexNet model
7. Display predicted emotion above face with bounding box

### ‚úî Real-Time Capabilities

* Real-time frame-by-frame prediction
* Multi-face emotion detection
* Smooth and optimized processing
* Option to test videos or images

This transforms the project from a research model into an **interactive, production-ready AI emotion recognition system**.

---

## üìÇ Project Structure

```
‚îú‚îÄ‚îÄ Alexnet_Emotion.ipynb         # Main training notebook
‚îú‚îÄ‚îÄ real_time_emotion.py          # Real-time CV script
‚îú‚îÄ‚îÄ README.md                     # Documentation
‚îú‚îÄ‚îÄ fer2013.csv                   # FER-2013 dataset (optional)
‚îî‚îÄ‚îÄ model/                        # Saved model files
```

---

## üõ† Technologies Used

* Python
* TensorFlow / Keras
* NumPy
* Pandas
* OpenCV
* Matplotlib
* scikit-learn
* TQDM

---

## üöÄ How to Run the Project

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Add the FER-2013 dataset

Place **fer2013.csv** inside the project folder.

### 4. Train the model

```bash
jupyter notebook Alexnet_Emotion.ipynb
```

### 5. Run real-time recognition

```bash
python real_time_emotion.py
```

---

## üìà Results (Add your values)

* Training Accuracy: **xx%**
* Validation Accuracy: **xx%**
* Test Accuracy: **xx%**
* Real-time prediction success: **Working**

---

## üì¨ Contact

**Shyamji Pandey**

LinkedIn: *https://www.linkedin.com/in/shyamji-pandey/*

Portfolio: *https://shyamjipandey.vercel.app/*
---
